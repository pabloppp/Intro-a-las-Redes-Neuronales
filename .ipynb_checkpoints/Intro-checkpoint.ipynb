{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La \"neurona\"\n",
    "\n",
    "![neurone](images/neurone.png)\n",
    "\n",
    "## Representación matemática\n",
    "\n",
    "\\begin{equation}\n",
    "y = W * x + b\n",
    "\\end{equation}\n",
    "\n",
    "Por ejemplo:\n",
    "\\begin{equation}\n",
    "0.2 = 0.05 * 4\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 4\n",
    "W = 0.05\n",
    "\n",
    "y = W * x\n",
    "\n",
    "print(\"y =\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "1.5 = W * 6\n",
    "\\end{equation}\n",
    "\n",
    "Partamos del mismo problema pero suponiendo que no conocemos el valor de W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 6\n",
    "W = random.uniform(0, 0.5)\n",
    "\n",
    "y = W * x\n",
    "print(\"W =\", W)\n",
    "print(\"y =\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queríamos que el resultado de la ecuación fuese 1.5, pero tenemos 0.389...\n",
    "\n",
    "Empecemos por calcular por cuanto nos hemos equivocado, usando el valor absoluto ya que tiene un mínimo\n",
    "\n",
    "<img width=400 src=\"images/absolute.png\">\n",
    "\n",
    "El valor absoluto nos da una pendiente de 1 en valores positivos, y una pendiente de -1 en valores negativos, podriamos usar eso como medida de cuanto nos hemos equivocado en W.\n",
    "\n",
    "Sin embargo, queremos algo más preciso, así que multiplicamos la pendiente del error (-1 o 1) por la pendiente de la ecuación inicial en base a W, que es x = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = W * x\n",
    "error = y - 1.5\n",
    "\n",
    "print(\"Queremos 1.5, pero y =\", y)\n",
    "print(\"Nuestro error es de\", abs(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a intentar modificar W en base a cuánto nos hemos equivocado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = W * x\n",
    "print(\"y = \", y)\n",
    "\n",
    "pendiente_error = -1 if error < 0 else 1 # -1 para valores negativos, 1 para valores positivos\n",
    "pendiente_w = x * pendiente_error\n",
    "\n",
    "nuevo_W = W - pendiente_w * 0.001\n",
    "y = nuevo_W * x\n",
    "\n",
    "print(\"Tras modificar W, y =\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si damos pasos muy grandes nos pasamos y nunca llegamos al mínimo, así que mejor dar pasos pequeñitos\n",
    "\n",
    "![lr](images/learningrate.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    y = W * x\n",
    "    error = y - 1.5\n",
    "    pendiente_error = -1 if error < 0 else 1 \n",
    "    pendiente_w = x * pendiente_error\n",
    "    W = W - pendiente_w * 0.0001\n",
    "\n",
    "y = W * x\n",
    "print(\"Tras 100 pasos, y =\", y, \"y W =\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y así tenemos nuestra primera neurona!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capas de neuronas\n",
    "\n",
    "Hemos visto una neurona con **un** valor de entrada y **un** valor de salida que equivale a una ecuación lineal:\n",
    "\n",
    "\\begin{equation}\n",
    "y = W * x + b\n",
    "\\end{equation}\n",
    "\n",
    "Pero... ¿Cómo sería una neurona con varios valores de entrada?  \n",
    "Sencillamente tendremos varios x y varios W.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "y = (W1 * x1) + (W2 * x2) + ... + (Wn * xn) + b\n",
    "\\end{equation}\n",
    "\n",
    "![lr](images/multi_in.png)\n",
    "\n",
    "¿Y si queremos varios valores de salida?  \n",
    "Como hemos visto antes, usamos una ecuación lineal que nos permite tener varios x, pero solo un y, por lo que para tener varios valores de salida necesitamos... ¡ MAS NEURONAS ! Lo que significa más ecuaciones:\n",
    "\n",
    "\\begin{equation}\n",
    "y1 = (W11 * x1) + (W21 * x2) + ... + (Wn1 * xn) + b1  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "y2 = (W12 * x1) + (W22 * x2) + ... + (Wn2 * xn) + b2 \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "...\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "ym = (W1m * x1) + (W2m * x2) + ... + (Wnm * xn) + bm \n",
    "\\end{equation}\n",
    "\n",
    "![lr](images/multi_in_out.png)\n",
    "\n",
    "Cada una de estas neuronas recibe todos los inputs y devuelve un único output, y tenemos una forma más bonita de representarlas, usando matrices:\n",
    "\n",
    "![lr](images/matrices.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De 'Shallow' a 'Deep' \n",
    "\n",
    "Ya sabemos cómo crear una capa de neuronas usando ecuaciones lineales, con multiples inputs y multiples outputs.\n",
    "\n",
    "Sin embargo, al ser operaciones lineales las relaciones que la red será capaz de extraer de los inputs serán lineales, así que para solucionar esto vamos a encadenar varias capas de neuronas, pasando los outputs de una de nuestras capas a la siguiente, y añadiendo una operación no-lineal entre ellas.\n",
    "\n",
    "Cuantas más capas añadamos, más compleja es la representación de los datos que podemos obtener:\n",
    "![lr](images/layer_sizes.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo esto ya parece muy dificil de hacer... No hay algo que me lo de ya hecho?\n",
    "\n",
    "Por supuesto, a la hora de trabajar con redes neuronales no definimos las operaciones una a una, ni tenemos que calcular nosotros mismos las pendientes de las distintas curvas, sino que usamos frameworks que nos abstraen de todo esto.\n",
    "\n",
    "Por ejemplo, probemos con PyTorch y su maravilloso autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[-1, 3, 5]]).float()\n",
    "Y = torch.tensor([[0.7, 1.3, 2.1]]).float()\n",
    "\n",
    "W1 = torch.randn(3, 6, requires_grad=True)\n",
    "W2 = torch.randn(6, 3, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([W1, W2], lr=0.01)\n",
    "\n",
    "for i in range(3000): \n",
    "    pred = torch.sigmoid(X.mm(W1)).mm(W2)\n",
    "    error = torch.abs(Y - pred).mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "torch.sigmoid(X.mm(W1)).mm(W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O lo que es todavía más facil, en vez de definir nosotros las dos matrices W, podemos usar capas pre-definidas de PyTorch!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[-1, 3, 5]]).float()\n",
    "Y = torch.tensor([[0.7, 1.3, 2.1]]).float()\n",
    "\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(3, 6),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(6, 3)\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(3000):\n",
    "    pred = network(X)\n",
    "    error = torch.abs(Y - pred).mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "network(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINI DEMO: NeuroCar\n",
    "\n",
    "<img width=200 style=\"display:inline-block;\" src=\"images/neurocar.png\" />\n",
    "<br/><br/><br/><br/>\n",
    "\n",
    "Notebook: [NeuroCar.ipynb](NeuroCar.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open \"NeuroCar/application.macosx/NeuroCar.app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
